\documentclass[11pt,a4paper,oneside]{article}
\usepackage{fullpage}
\usepackage[none]{hyphenat} 
\usepackage{natbib}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}


\begin{document}

\begin{titlepage}
    \begin{center}
        \textsc{\large Eastern Michigan University}\\[1.5cm]
        \textsc{\large Computer Science Department}\\
        \textsc{\large Masters Thesis Proposal}\\[0.5cm]
        \HRule\\[0.4cm]
        { \huge \bfseries  Realtime Raytracing }\\[0.4cm]
        \HRule\\[1.5cm]

        % Author and supervisor
        \begin{minipage}{0.45\textwidth}
            \begin{flushleft} \large
                \emph{Author:}\\
                Byron \textsc{Heads} \\
                \small Eastern Michigan University\\
                \small Computer Science Department \\
            \end{flushleft}
        \end{minipage}
        \begin{minipage}{0.45\textwidth}
            \begin{flushright} \large
                \emph{Thesis Advisor:} \\
                Dr.~William \textsc{Sverdlik}\\
                \small Eastern Michigan University\\
                \small Computer Science Department
            \end{flushright}
        \end{minipage}

        \vfill
        %{ \large \textbf{Abstract Summary}}\\

		\begin{center}
			\includegraphics[scale=0.45]{cover.png} 
		\end{center}
	
    
        \HRule\\[0.5cm]
        { \large \today }
    \end{center}
\end{titlepage}

\begin{abstract}



\end{abstract}
%\newpage 
%\tableofcontents
\newpage 

\section{ Introduction }
The field of computer graphics has push the need for faster hardware,  and more efficient algorithms and data structures.  Producing life like and stunning computer generated graphics,  computer interfaces, computer aided design in manufacturing, a multi-billion dollar game industry, and life like CGI movies\cite{gaming:2007} have made computer graphics an important field of study.

There are two dominant rendering algorithms in computer graphics.  The most widely used algorithm is the z-buffer.  This algorithm is based around sorting triangles in a depth buffer.  The other algorithm is ray casting.  This algorithm is based on the physics of light.  Both algorithms are used today, but often for different purposes.  

\section{Z-Buffering}

Computer graphics used in modern games and simulation environments that require real time updates to its environment are based around the \textbf{z-buffering} algorithm.  Z-buffering builds a scene by computing the depth of triangles in a scene from a view-point,  known as the \textbf{eye}.  The algorithm is simple and each pixel can be computed with stream processors that are commonly  used on modern GPUs.  Hardware implementations of z-buffers commonly have two frame buffers for color and a depth buffer.    The color buffer is split into the front buffer and the back buffer.  The back buffer is where the algorithm is rendering to, and the front buffer is drawn to the screen.  Once the back buffer it filled it is swapped with the front buffer, this is normally done with a simple pointer swap.  The algorithm for z-buffer is as follows \cite{fast:2008}:

\begin{algorithm}
\begin{algorithmic}[1]
\STATE $C[ ] \gets \textit{background color}$ 
\STATE $Z[ ] \gets \infty$
\FOR{ all \textit{N} triangles }
	\FOR{ each pixel p in triangle }
		\STATE $c \gets \textit{new color}$
		\STATE $z \gets \textit{new depth}$
		\IF{ $z < Z_{p} $ }
			\STATE $Z_{p} \gets z$
			\STATE $C_{p} \gets c$
		\ENDIF
	\ENDFOR
\ENDFOR
\end{algorithmic}
\caption{Example of the z-buffer algorithm}
\label{z-buffer}
\end{algorithm}

This algorithm works by tracking the depth of the color for each given pixel that is rendered in the back buffer.  This algorithm is fast and easy to implement but nowhere in the algorithm is light, shadow, reflection, or refraction calculated.  To produce these effects simple ray casting is often needed.  Z-buffering only renders from a single point, the eye, but to calculate shadow or reflection the algorithm needs to be able to work from any point in space.  The solution relies in building a better physics based model for light.

\section{Ray Tracing}

To make a better model we first need to understand how light works.  In the real world a light source emit photons that collide with an object which changes the energy state of the photon.  This photon is then reflected off of the object and then enters into our eyes, which our brain interpreters as a color.  One problem with modelling this is that only a very small percent of the emitted light is actually seen.  A better solution exists in ray tracing.  

A more efficient way to model realistic light is to trace photons that enter the eye back to its source of light.  Each photon can be computed independently of each other making ray tracing inherently parallel.  An initial point is used as the light focal point, this is known as the \textit{eye}.  A photon is traced backwards from the eye through an image plane that is in front of the eye.  This image plane acts like film in a pinhole camera.  

\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.6]{pineholecamera.png} 
\caption{Pinhole camera}
\label{pinhole-camera}
\end{center}
\end{figure}

In a pinhole camera the image is upside down on the film because the photons pass through the focal point and cross the central plain.  The camera can be simplified by moving the film in front of the focal point.

 \begin{figure}[H]
 \begin{center}
\includegraphics[scale=0.6]{raycamera.png} 
\caption{Ray tracer camera}
\label{ray-camera}
\end{center}
\end{figure}

Algorithm \ref{ray-trace} is a simple implementation that produces images similar to the z-buffering algorithm.  The scene consists of a list of geometric objects.  Unlike z-buffering any shape that collision with a ray can be detected can be used.  The image buffer is an array that holds the resulting output colors from the algorithm.  A ray consists of a starting vector and a normalized direction vector.  A ray is created at the eye or starting vector, in the direction of each pixel in the image plane.  The color of the pixel is set to the color of the closest object that the ray collides with.  

\begin{algorithm}[H]
\begin{algorithmic}[1]
\STATE $O[ ] \gets \textit{All objects in scene}$ 
\STATE $I[] \gets 0$ \COMMENT{Clear image buffer}
\STATE
\FOR{ each pixel p in I }
	\STATE $I_{p} \gets raytrace( castray( eye, p ))$
\ENDFOR
\STATE 
\STATE \textit{color} \textbf{function} raytrace(  R )
	\STATE $c  \gets \textit{ambient color } $
	\STATE $d \gets \infty $
	\FOR{ each object o in O[] }
		\IF{ collision( R, o )  }
			\IF{ $distance( \textit{eye}, o ) < d$ }
				\STATE $d \gets distance( \textit{eye}, o )$
				\STATE $c \gets color( o )$
			\ENDIF
		\ENDIF
	\ENDFOR
	\STATE \textbf{return} c

\end{algorithmic}
\caption{Simple ray tracing algorithm}
\label{ray-trace}
\end{algorithm}

Adding light and shadow to this algorithm is done by computing the amount of light at each point of collision by casting a ray from that point to each light source in the scene.  If their is an object between the collision point and the light then the point is in shadow and does not get light added it its color, but if the rays closest collision is with the light source then the points color is computed..  The color of a point is computed from three components: \textit{ambient}, \textit{diffuse}, and \textit{specular} lighting\cite{kalinini:2008}.

Surfaces can be made reflective or refractive by using the recursion.  If a surface is reflective a new ray is computed at the point of collision using the surface normal at that point as the reflection plane.  This new ray is used to computed the reflected color.  Using this ray tracers can produce shiny surfaces and mirrors.  

Refraction is handled in the same way with the exception of the way the refracted ray is computed.  Refracted rays are bent into the object that depends on the properties of the objects martial.  This handles light passing through transparent martial like glass and water. Algorithm \ref{ray-trace-full} shows an example program using lighting, reflections, and refractions.
  
\begin{algorithm}[H]
\begin{algorithmic}[1]
\STATE $O[\ ] \gets \textit{All objects in scene}$ 
\STATE $L[\ ] \gets \textit{All lights in scene}$
\STATE $I[\ ] \gets 0$ \COMMENT{Clear image buffer}
\STATE
\FOR{ each pixel p in I }
	\STATE $I_{p} \gets raytrace( castray( eye, p ))$
\ENDFOR
\STATE 
\STATE \textit{color} \textbf{function} raytrace(  R, depth )
	\STATE $c  \gets \textit{ambient color } $
	\STATE $d \gets \infty $
	\STATE $s \gets \textit{NULL}$
	\FOR{ each object o in O[] }
		\IF{ collision( R, o )  }
			\IF{ $distance( \textit{eye}, o ) < d$ }
				\STATE $d \gets distance( \textit{eye}, o )$
				\STATE $s \gets o$
			\ENDIF
		\ENDIF
	\ENDFOR
	\IF{ $s\ \textbf{NOT}\ \textit{NULL}$ }
		\STATE \COMMENT{Find direct light on object s}
		\STATE $pi \gets pointOfCollision( R, s )$
		\FOR{ each light l in L }
			\STATE $lr \gets castRay( pi, l )$
			\STATE $ld \gets distance( pi, l )$
			\STATE $shade \gets 1$
			\FOR{ each object o in O }
				\IF{ collision( lr, o ) \textbf{AND} distance( lr, o ) < ld }
					\STATE $shade \gets 0$				
				\ENDIF
				\STATE $c \gets c +( diffuse( s, l ) + specular( s, l )) * shade$ 
			\ENDFOR
		\ENDFOR
		\STATE \COMMENT{Recursively compute reflections}
		\IF{ $reflectivity( s ) > 0\ \textbf{AND}\ depth < depthMax$ }
			\STATE $rr \gets reflection( pi, normal( s, pi ))$
			\STATE $c \gets c + raytrace( rr ) * reflectivity( s )$
		\ENDIF
		\STATE \COMMENT{Recursively compute refraction}
		\IF{ $transparency( s ) > 0\ \textbf{AND}\ depth < depthMax$ }
			\STATE $rr \gets refraction( pi, normal( s, pi ), s )$
			\STATE $c \gets c + raytrace( rr ) * transparency( s )$
		\ENDIF
	\ENDIF
	\STATE \textbf{return} c

\end{algorithmic}
\caption{ Ray tracing algorithm with lighting }
\label{ray-trace-full}
\end{algorithm}
\newpage

The images produced with this algorithm produces overly sharp edges around objects and shadows, and pixelation To clean up the image anti aliasing and soft shadows can be added.  Adding anti aliasing is done by casting more rays through a pixel and then averaging the resulting colors together.  To do this the area in space that the pixel covers needs to be subdivided into smaller regions.  A ray is cast from the eye through these regions.  The ray can be cast through the center for a shaper image, or randomly for softer edges.  Anti aliasing can increase the computation cost dramatically.  Each new ray can create two new rays for reflection and refraction.

\begin{figure}[H]
\includegraphics[scale=0.6]{aa.png} 
\caption{Anti aliasing for a single pixel.}
\label{aa}
\end{figure}

Soft shadows are used to make a softer transition from light to shadow.     The simple lighting model cast a ray from the point of collision to the center of a light source, but points that are on the edge of a shadow may get partial light.  In the real world a light bulb has volume.  A soft shadow is computed by casting several rays from the collision point to a point in the lights volume, the results are averaged together to computer the finial color.  Theses rays are often cast randomly through a uniform subdivision of the light sources volume.  Most ray tracers only use soft shadowing on simple shapes like planes and polygons.  Soft shadows can be expensive to compute since each light ray needs to be tested if they are blocked by an object.

\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.21]{result1.png} 
\caption{Non-optimized ray traced image with 8 light, and 80 spheres.  Took 34 minutes to render.}
\label{result1}
\end{center}
\end{figure}

\section{Run Time Complexity}
The runtime of algorithm \ref{ray-trace} can be computed as $O(n^2)$.    The ray trace function iterates over all of the objects in the scene to test for a ray-object collision.  The ray trace function is called for every pixel in the output image.   The algorithm can be improved by using a different data structure to store the scenes objects and lights.

The runtime of the full ray tracer algorithm \ref{ray-trace-full} is more complex to compute.  Without the recursive calls, the ray trace function has a $O(n^2 + n^3 )$.  This changes when we allow for recursion.  Each ray can cast two more rays up to a set max depth.  Without a max depth we could end up with infinite recursion.  This leaves us with a runtime with $O(2kn^2+2kn^3)$.  Adding soft shadows and anti aliasing can make this even more complex.

Using a linear list of objects and lights creates a serious performance hit.  Using a data structure that reduces the number of objects to test for ray-object collisions will give a dramatic performance boost to the algorithm.


\section{Real-time}
I am proposing to implement a real-time ray tracer.  I will research algorithms and data strictures to reduce the run time of a ray tracer.  I will research techniques in CPU parallelism for algorithms and data structures.  I believe it is possible to speed up the algorithm by either parallel ray casting or parallel collision detection.

Much of the research in real-time ray tracing is concentrated around fast ray-object collision testing.  One of the simplest ways to speed this up is by reducing the number of collision tests\cite{kd:2005}.
Much of this research is about parallel kd-tree ray tracing on the GPU\cite{kd:2007}\cite{fkd:2007}.  I believe much of this research can be applied to fast CPU based kd-tree ray tracing\cite{kd:2006}.

\newpage
\listofalgorithms
\listoffigures
%\listoftables
\bibliographystyle{plain}
\bibliography{proposal}

\end{document}

